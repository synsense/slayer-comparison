{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "from tbparse import SummaryReader\n",
    "import yaml\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "from os.path import exists\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.ion()\n",
    "# sns.set(font_scale=1, style=\"white\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_file = 'dataframe.pd'\n",
    "if exists(df_file):\n",
    "  with open(df_file, 'rb') as f:\n",
    "    df = pickle.load(f)\n",
    "    # df = df.reset_index(drop=True)\n",
    "else:\n",
    "  param_list = [\"tau_mem\", \"scale_grad\", \"width_grad\", \"optimizer\",] # \"batch_size\", \"decoding_func\", \"encoding_dim\", \"hidden_dim\", \"learning_rate\", \"n_hidden_layers\", \"spike_threshold\"\n",
    "  dfs = []\n",
    "  for root, dirs, files in os.walk(Path('lightning_logs/ssc')):\n",
    "    results = None\n",
    "    if 'hparams.yaml' in files:\n",
    "      results = SummaryReader(root, pivot=True)\n",
    "      df = results.scalars\n",
    "      hp = results.hparams\n",
    "      # drop a few columns that we don't use\n",
    "      df = df[df.columns[~df.columns.str.endswith(\"weight_epoch\") & ~df.columns.str.endswith(\"weight_step\")]]\n",
    "      df = df.drop(columns='hp_metric')\n",
    "      # add hyperparameters to table\n",
    "      df['method'] = root.split(\"/\")[2].upper() # method name, exodus or slayer\n",
    "      df['run'] = root.split(\"/\")[-1] # we ran each experiment 3 times, so version_0, 1 or 2\n",
    "      for param in param_list:\n",
    "        df[param] = hp[param][0]\n",
    "      dfs.append(df)\n",
    "  df = pd.concat(dfs, ignore_index=True)\n",
    "  df.to_pickle('dataframe.pd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[(df[\"optimizer\"] == \"adam\") & (df[\"run\"] == \"version_0\")]\n",
    "selection = df.query(\"(optimizer == 'sgd')\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.relplot(data=selection, x=\"step\", y=\"valid_acc\", col=\"tau_mem\", hue=\"scale_grad\", kind=\"line\") #  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b0d71d32d2b596f460291e0fcc4c5be95d741b16cf87a49532d3e8154ab3bc33"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('synsense')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
