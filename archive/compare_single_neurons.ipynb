{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "from single_neuron_models import ExodusNeuron, SlayerNeuron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tau_mem = torch.tensor(30.)\n",
    "tau_syn = 30.\n",
    "spike_threshold = 1\n",
    "n_time_steps = 100\n",
    "width_grad = 1\n",
    "scale_grad = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'weight': 0.01,\n",
    "    'tau_mem': tau_mem,\n",
    "    'spike_threshold': spike_threshold,\n",
    "    'width_grad': width_grad,\n",
    "    'scale_grad': scale_grad,\n",
    "}\n",
    "exodus_neuron = ExodusNeuron(**params).cuda()\n",
    "slayer_neuron = SlayerNeuron(n_time_steps=n_time_steps, **params).cuda()\n",
    "\n",
    "input_spike_time = 10\n",
    "target_spike_time = 30\n",
    "input = torch.zeros(1, 100, 1, 1, 1)\n",
    "target = torch.zeros_like(input)\n",
    "input[:, input_spike_time] = 1\n",
    "target[:, target_spike_time] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out1 = exodus_neuron(input.cuda())\n",
    "v_mem1 = exodus_neuron.lif.v_mem_recorded\n",
    "\n",
    "out2 = slayer_neuron(input.cuda())\n",
    "psp_pre = slayer_neuron.psp_pre\n",
    "psp_post = slayer_neuron.psp_post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(2, 1, sharex=True, figsize=(8, 6))\n",
    "\n",
    "ax1.plot(out1.squeeze().cpu().detach().numpy(), label='output')\n",
    "ax1.plot(v_mem1.squeeze().cpu().detach().numpy(), label='LIF v_mem')\n",
    "ax1.legend()\n",
    "ax1.set_title('Exodus neuron')\n",
    "\n",
    "ax2.plot(out2.squeeze().cpu().detach().numpy(), label='output')\n",
    "# ax2.plot(psp_pre.squeeze().cpu().detach().numpy(), label='psp pre')\n",
    "ax2.plot(psp_post.squeeze().cpu().detach().numpy(), label='psp post')\n",
    "ax2.legend()\n",
    "ax2.set_title('SLAYER CUBALIF neuron')\n",
    "ax2.set_xlabel('time steps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, input, target, lr=1e-2):\n",
    "    criterion = nn.MSELoss()\n",
    "    optimiser = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    param_trace = []\n",
    "    loss_trace = []\n",
    "    grad_trace = []\n",
    "\n",
    "    input, target = input.cuda(), target.cuda()\n",
    "\n",
    "    for i in tqdm(range(2000)):\n",
    "        if model.spiking_layers:\n",
    "            model.reset_states()\n",
    "        model.zero_grad()\n",
    "        optimiser.zero_grad()\n",
    "\n",
    "        output = model(input)\n",
    "\n",
    "        regulariser = 0.01 * (output.sum() - 1) ** 2\n",
    "        loss = criterion(output, target) * n_time_steps + regulariser\n",
    "\n",
    "        if loss == 0:\n",
    "            break\n",
    "\n",
    "        loss_trace.append(loss.item())\n",
    "        loss.backward()\n",
    "        optimiser.step()\n",
    "\n",
    "        param_trace.append(model.lin.weight.item())\n",
    "        grad_trace.append(model.lin.weight.grad.item())\n",
    "\n",
    "    return output, param_trace, loss_trace, grad_trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=1e-3\n",
    "output, param_trace, loss_trace, grad_trace = train(exodus_neuron, input, target, lr=lr)\n",
    "output2, param_trace2, loss_trace2, grad_trace2 = train(slayer_neuron, input, target, lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax0, ax1, ax2) = plt.subplots(3, 1, sharex=True, figsize=(16, 8))\n",
    "\n",
    "ax0.plot(loss_trace, label='EXODUS')\n",
    "ax0.plot(loss_trace2, label='SLAYER')\n",
    "ax0.set_ylabel('loss')\n",
    "ax0.legend()\n",
    "ax1.plot(param_trace, label='EXODUS')\n",
    "ax1.plot(param_trace2, label='SLAYER')\n",
    "ax1.set_ylabel('weight')\n",
    "ax1.legend()\n",
    "ax2.plot(grad_trace, label='EXODUS')\n",
    "ax2.plot(grad_trace2, label='SLAYER')\n",
    "ax2.set_ylabel('weight grad')\n",
    "ax2.set_xlabel('epochs')\n",
    "ax2.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(2, 1, sharex=True, figsize=(16, 8))\n",
    "\n",
    "ax1.plot(param_trace, loss_trace)\n",
    "ax2.plot(param_trace, grad_trace)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e6cb2531ff3209080f8ff5f4f1b83a3f6fd522559ade981afeb04664418b3902"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
